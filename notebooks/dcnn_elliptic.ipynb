{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Convolutional Neural Network for sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, format='',\n",
    "                level=logging.INFO, datefmt=None)\n",
    "logger = logging.getLogger('elliptic_scouting')\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from evaluation.model_performance import *\n",
    "\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "KTOP = 2\n",
    "\n",
    "def get_dmaxp(d, in_size, tot_L):\n",
    "    m = (tot_L - in_size) * d // tot_L\n",
    "    return max(KTOP, m)\n",
    "\n",
    "def conv1dOShape(l_in, k, s=2, p=0):\n",
    "    return (l_in - k + 2*p) // s + 1\n",
    "\n",
    "class DCNN(nn.Module):\n",
    "    def __init__(self, in_channels, d, tot_l=2, wide=False):\n",
    "        super(DCNN, self).__init__()\n",
    "        self._in_channels = in_channels\n",
    "        self._d = d\n",
    "        self._k = self._d + 3 if wide else 3 # input size s^{m x d} d number of features\n",
    "        self._tot_l = tot_l\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(self._in_channels, 5, self._k, stride=2, dtype=torch.float),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool1d(get_dmaxp(d, conv1dOShape(self._d, self._k), self._tot_l)),\n",
    "            nn.Conv1d(5, 3, 3, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool1d(get_dmaxp(d, conv1dOShape(conv1dOShape(self._d, self._k), 3), self._tot_l)),\n",
    "            nn.Flatten(0),\n",
    "            nn.Linear(30, 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = torch.tensor(x, device='cpu', dtype=torch.float32)\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "class EllipticDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.asarray(self._X.iloc[idx].values, dtype=np.float32)\n",
    "        y = np.asarray(self._y.iloc[idx], dtype=np.float16)\n",
    "        return torch.from_numpy(x), torch.from_numpy(y).type(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time_step = 49\n",
    "last_train_time_step = 34\n",
    "only_labeled = True\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = run_elliptic_preprocessing_pipeline(last_train_time_step=last_train_time_step,\n",
    "                                                                             last_time_step=last_time_step,\n",
    "                                                                             only_labeled=only_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.shape, y_train.shape, X_test_df.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "train_ds = EllipticDataset(X_train_df, y_train)\n",
    "test_ds = EllipticDataset(X_test_df, y_test)\n",
    "train_ds = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_ds = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds:\n",
    "    print(x.shape)\n",
    "    print(x.dtype)\n",
    "    print(y.shape)\n",
    "    print(y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DCNN(BATCH_SIZE, X_train_df.shape[1])\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1 = nn.Conv1d(1, 5, 3, stride=2)\n",
    "# maxp1 = nn.MaxPool1d(get_dmaxp(d, conv1dOShape(d, 3), 2))\n",
    "# conv2 = nn.Conv1d(5, 3, 3, stride=2)\n",
    "# maxp2 = nn.MaxPool1d(get_dmaxp(d, conv1dOShape(conv1dOShape(d, 3), 3), 2))\n",
    "# fl = nn.Flatten(0)\n",
    "# ln = nn.Linear(3, 2)\n",
    "# sm = nn.Softmax(dim=0)\n",
    "\n",
    "# x1 = conv1(x)\n",
    "# x2 = maxp1(x1)\n",
    "# x3 = conv2(x2)\n",
    "# x4 = maxp2(x3)\n",
    "# x5 = fl(x4)\n",
    "# x6 = ln(x5)\n",
    "# out = sm(x6)\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds:\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    print(type(x))\n",
    "    print(net(x).view(-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "ce_loss = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters())\n",
    "\n",
    "for x, y in train_ds:\n",
    "    pred = net(x)\n",
    "    ce_loss(pred, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "ce_loss = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=net.parameters())\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for x, y in train_ds:\n",
    "        net.zero_grad()\n",
    "        y_pred = net(x)\n",
    "        loss = ce_loss(y_pred, y)\n",
    "        # calculate gradients of loss with respect model params\n",
    "        loss.backward()\n",
    "        # update params\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'epoch {epoch} loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for x, y in test_ds:\n",
    "    pred = net(x)\n",
    "    loss = ce_loss(pred, y)\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.asarray(losses)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac9f23b16c7e65327bfbfb11aff8e700df5fb40263e5264f605c5c0a67194634"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
