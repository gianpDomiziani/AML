{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Convolutional Neural Network for sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# evaluation\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, format='',\n",
    "                level=logging.INFO, datefmt=None)\n",
    "logger = logging.getLogger('elliptic_scouting')\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, Image\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils import *\n",
    "from evaluation.model_performance import *\n",
    "\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "KTOP = 2\n",
    "\n",
    "def get_dmaxp(d, in_size, tot_L):\n",
    "    m = (tot_L - in_size) * d // tot_L\n",
    "    return max(KTOP, m)\n",
    "\n",
    "def conv1dOShape(l_in, k, s=2, p=0):\n",
    "    return (l_in - k + 2*p) // s + 1\n",
    "\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self, in_features, focal_loss=False):\n",
    "        super(Baseline, self).__init__()\n",
    "        self._in_features = in_features\n",
    "        self.l1 = nn.Linear(self._in_features, 32)\n",
    "        self.l2 = nn.Linear(32, 8)\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self._focal = focal_loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = self.output(x).reshape(1)\n",
    "        if not self._focal:\n",
    "            return torch.sigmoid(x)\n",
    "        else:\n",
    "            return x.reshape(1)\n",
    "\n",
    "\n",
    "class DCNN(nn.Module):\n",
    "    def __init__(self, in_channels, d, focal_loss=True, tot_l=2, wide=False):\n",
    "        super(DCNN, self).__init__()\n",
    "        self._in_channels = in_channels\n",
    "        self._d = d\n",
    "        self._k = self._d + 3 if wide else 3 # input size s^{m x d} d number of features\n",
    "        self._tot_l = tot_l\n",
    "        self._focal_loss = focal_loss\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self._in_channels, 5, self._k, stride=1, dtype=torch.float)\n",
    "        self.conv2 = nn.Conv1d(5, 3, 3, stride=1)\n",
    "        self.conv3 = nn.Conv1d(3, 3, 3, stride=1)\n",
    "        self.f1 = nn.Linear(57, 14)\n",
    "        self.output = nn.Linear(14, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.leaky_relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool1d(F.leaky_relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool1d(F.leaky_relu(self.conv3(x)), 2)\n",
    "        x = torch.flatten(x, 0)\n",
    "        x = self.f1(x)\n",
    "        if self._focal_loss:\n",
    "            return self.output(x)\n",
    "        else:\n",
    "            return torch.sigmoid(self.output(x))\n",
    "    \n",
    "\n",
    "class EllipticDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.asarray(self._X.iloc[idx].values, dtype=np.float32)\n",
    "        y = np.asarray(self._y.iloc[idx], dtype=np.float16)\n",
    "        return torch.from_numpy(x), torch.from_numpy(y).type(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(1, 166)\n",
    "t1 = nn.Conv1d(1, 5, 3)(t)\n",
    "t2 = F.max_pool1d(t1, 2)\n",
    "t3 = nn.Conv1d(5, 3, 3)(t2)\n",
    "t4 = F.max_pool1d(t3, 2)\n",
    "t1.shape, t2.shape, t3.shape, t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time_step = 49\n",
    "last_train_time_step = 34\n",
    "only_labeled = True\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = run_elliptic_preprocessing_pipeline(last_train_time_step=last_train_time_step,\n",
    "                                                                             last_time_step=last_time_step,\n",
    "                                                                             only_labeled=only_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.shape, y_train.shape, X_test_df.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "train_ds = EllipticDataset(X_train_df, y_train)\n",
    "test_ds = EllipticDataset(X_test_df, y_test)\n",
    "train_ds = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_ds = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds:\n",
    "    print(x.shape)\n",
    "    print(x.dtype)\n",
    "    print(y.shape)\n",
    "    print(y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DCNN(BATCH_SIZE, X_train_df.shape[1])\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(X_test_df.shape[1], focal_loss=True)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1 = nn.Conv1d(1, 5, 3, stride=2)\n",
    "# maxp1 = nn.MaxPool1d(get_dmaxp(d, conv1dOShape(d, 3), 2))\n",
    "# conv2 = nn.Conv1d(5, 3, 3, stride=2)\n",
    "# maxp2 = nn.MaxPool1d(get_dmaxp(d, conv1dOShape(conv1dOShape(d, 3), 3), 2))\n",
    "# fl = nn.Flatten(0)\n",
    "# ln = nn.Linear(3, 2)\n",
    "# sm = nn.Softmax(dim=0)\n",
    "\n",
    "# x1 = conv1(x)\n",
    "# x2 = maxp1(x1)\n",
    "# x3 = conv2(x2)\n",
    "# x4 = maxp2(x3)\n",
    "# x5 = fl(x4)\n",
    "# x6 = ln(x5)\n",
    "# out = sm(x6)\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for x, y in train_ds:\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        print(type(x))\n",
    "        print(net(x).view(-1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 5\n",
    "# ce_loss = torch.nn.BCELoss()\n",
    "# with torch.no_grad():\n",
    "#  for i, data in enumerate(train_ds):\n",
    "#     pred = baseline(data[0])\n",
    "#     #print(ce_loss(pred, data[1]))\n",
    "#     print(sigmoid_focal_loss(pred, data[1]))\n",
    "#     if i == 3:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "ce_loss = torch.nn.BCELoss()\n",
    "focal_loss = sigmoid_focal_loss\n",
    "# optimizer = torch.optim.Adam(params=baseline.parameters())\n",
    "optimizer = torch.optim.Adam(params=net.parameters())\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    net.train()\n",
    "    for x, y in train_ds:\n",
    "        #y_pred = baseline(x)\n",
    "        y_pred = net(x)\n",
    "        #loss = ce_loss(y_pred, y)\n",
    "        loss = focal_loss(y_pred, y) # pred is the \n",
    "        # calculate gradients of loss with respect model params\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update params\n",
    "        optimizer.step()\n",
    "    print(f'epoch {epoch} loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "preds = []\n",
    "trues = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_ds:\n",
    "        #pred = baseline(x)\n",
    "        pred = net(x)\n",
    "        loss = focal_loss(pred, y)\n",
    "        trues.append(y.data.cpu().numpy())\n",
    "        losses.append(loss.item())\n",
    "        preds.append(torch.sigmoid(pred).data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.asarray(preds)\n",
    "bin_preds = np.asarray(preds > .5).astype(np.half)\n",
    "cf_matrix = confusion_matrix(trues, bin_preds)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title=None, xtickslabels=None, ytickslabels=None):\n",
    "  precision, recall, f1score, support = precision_recall_fscore_support(y_true, y_pred)\n",
    "  display(Markdown(f'Precision {precision}, recall {recall}, f1score {f1score}, support {support}'))    \n",
    "  ax = skplt.metrics.plot_confusion_matrix(\n",
    "          y_true,\n",
    "          y_pred,\n",
    "          normalize=True,\n",
    "          figsize=(10, 8),\n",
    "          title=title\n",
    "         )\n",
    "    \n",
    "  if xtickslabels is not None:\n",
    "    ax.set_xticklabels(xtickslabels)\n",
    "\n",
    "  if ytickslabels is not None:\n",
    "    ax.set_yticklabels(ytickslabels)\n",
    "        \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(trues, bin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac9f23b16c7e65327bfbfb11aff8e700df5fb40263e5264f605c5c0a67194634"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
